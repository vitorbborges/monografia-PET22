{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from utils import dataset, load_bow\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "from names_matcher import NamesMatcher\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\n",
    "    'Publication Type', \\\n",
    "    'Venue', \\\n",
    "    'Author Full Names', \\\n",
    "    'Article Title', \\\n",
    "    'Abstract', \\\n",
    "    'Publication Date', \\\n",
    "    'Publication Year']\n",
    "\n",
    "venues = dataset()[col]\n",
    "venues = venues.dropna(subset=['Abstract'])\n",
    "venues['Abstract Lemmatized'] = load_bow('25_venues')\n",
    "venues = venues.dropna(subset=['Publication Date'])\n",
    "venues['Date'] = (venues['Publication Date']+'-'+venues['Publication Year']).apply(lambda x: datetime.strptime(x, '%b-%Y'))\n",
    "query_dataframe = pd.read_csv('./database/query_dataframe.csv', index_col=1)\n",
    "venues['Venue Full Name'] = venues['Venue'].apply(lambda x : query_dataframe.loc[x, 'Nome'])\n",
    "venues = venues.sort_values(by='Date')\n",
    "venues.index = range(len(venues))\n",
    "\n",
    "df = pd.read_csv(f'./KLD/distributions_{w}.csv')\n",
    "venues['LDA Distribution'] = df['LDA Distribution']\n",
    "\n",
    "for c in [co for co in df.columns if co[-1:] == str(w)]:\n",
    "    venues[c] = df[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = venues['Author Full Names']\n",
    "authors = [names.split(';') for names in authors]\n",
    "authors = [[name.strip().upper() for name in names] for names in authors]\n",
    "authors = list(authors)\n",
    "authors = list(chain.from_iterable(authors))\n",
    "authors = sorted(list(set(authors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_dict = {}\n",
    "\n",
    "for author in authors:\n",
    "    authors_dict[author] = []\n",
    "\n",
    "for index, row in venues.iterrows():\n",
    "    for author in row['Author Full Names'].split(';'):\n",
    "        authors_dict[author.upper().strip()].append(row['Article Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = {k: str(v) for k, v in authors_dict.items()}\n",
    "authors_df = pd.DataFrame(authors_df, index = ['Papers']).T\n",
    "authors_df['publications'] = authors_df['Papers'].apply(lambda x: len(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = authors_df.iloc[np.where(authors_df['publications'] >= 37)].sort_index()\n",
    "top['pids'] = np.nan\n",
    "top.to_csv('./database/top1000authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_author(name, authors):\n",
    "    return NamesMatcher()([name], authors)[0][0]\n",
    "\n",
    "\n",
    "def make_request(session, pub, retries=10, backoff_factor=1):\n",
    "    url = f'https://dblp.org/search/publ/api?q={pub}&format=xml'\n",
    "    \n",
    "    for retry in range(retries):\n",
    "        try:\n",
    "            time.sleep(backoff_factor)  # Wait for at least a second between requests\n",
    "            response = session.get(url)\n",
    "            if response.status_code == 429:  # Too Many Requests\n",
    "                raise requests.exceptions.RequestException(\"Too Many Requests\")\n",
    "            return response.text\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if retry < retries - 1:\n",
    "                sleep_time = backoff_factor * (2 ** retry) + random.uniform(0, 0.1)\n",
    "                time.sleep(sleep_time)\n",
    "                continue\n",
    "            else:\n",
    "                raise e\n",
    "from collections import Counter           \n",
    "async def start_async_process():\n",
    "    with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        with requests.Session() as session:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            tasks = [loop.run_in_executor(executor, make_request, *(session,f'{i} {name}')) for i in pubs]\n",
    "            pids = []\n",
    "            for response in await asyncio.gather(*tasks):\n",
    "                soup = BeautifulSoup(response, 'xml')\n",
    "                retries = 0\n",
    "                while (hits := soup.find('hits')) and hits['computed'] == '0' and retries < 10:\n",
    "                    pub = random.sample(eval(top.loc[name]['Papers']), 1)\n",
    "                    if retries > 5:\n",
    "                        req = make_request(session, f'{pub}')\n",
    "                    else:\n",
    "                        req = make_request(session, f'{pub} {name}')\n",
    "                    soup = BeautifulSoup(req, 'xml')\n",
    "                    retries += 1\n",
    "                author_pids = list(map(lambda x: x['pid'] ,soup.findAll('author')))\n",
    "                author_names = list(map(lambda x: x.text ,soup.findAll('author')))\n",
    "                if len(author_pids) > 0:\n",
    "                    pids.append(author_pids[find_author(name, author_names)].split('-')[0])\n",
    "            if pids != []:\n",
    "                pids_count = Counter(pids)\n",
    "                top.loc[name, 'pids'] = pids_count.most_common(1)[0][0]\n",
    "                top.loc[name, 'names'] = str(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 895/895 [6:28:58<00:00, 26.08s/it]   \n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "top = pd.read_csv('./database/top1000authors.csv')\n",
    "top.set_index('Unnamed: 0', inplace=True)\n",
    "missing = top[top['pids'].isna()].index\n",
    "top['names'] = np.nan\n",
    "\n",
    "for name in tqdm(missing):\n",
    "    pubs = random.sample(eval(top.loc[name]['Papers']), 11)\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = asyncio.ensure_future(start_async_process())\n",
    "    asyncio.run(future)\n",
    "\n",
    "still_missing = top[top['pids'].isna()].index\n",
    "for name in tqdm(still_missing):\n",
    "    pubs = random.sample(eval(top.loc[name]['Papers']), 11)\n",
    "    pids = []\n",
    "    with requests.Session() as session:\n",
    "        for pub in pubs:\n",
    "            req = make_request(session, f'{pub}')\n",
    "            soup = BeautifulSoup(req, 'xml')\n",
    "            retries = 0\n",
    "            while (hits := soup.find('hits')) and hits['computed'] == '0' and retries < 10:\n",
    "                pub = random.sample(eval(top.loc[name]['Papers']), 1)\n",
    "                if retries > 5:\n",
    "                    req = make_request(session, f'{pub}')\n",
    "                else:\n",
    "                    req = make_request(session, f'{pub} {name}')\n",
    "                soup = BeautifulSoup(req, 'xml')\n",
    "                retries += 1\n",
    "            author_pids = list(map(lambda x: x['pid'] ,soup.findAll('author')))\n",
    "            author_names = list(map(lambda x: x.text ,soup.findAll('author')))\n",
    "            if len(author_pids) > 0:\n",
    "                pids.append(author_pids[find_author(name, author_names)].split('-')[0])\n",
    "\n",
    "    if pids != []:\n",
    "        pids_count = Counter(pids)\n",
    "        top.loc[name, 'pids'] = pids_count.most_common(1)[0][0]\n",
    "        top.loc[name, 'names'] = str(pids)\n",
    "\n",
    "top.to_csv('./database/top1000authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "top.loc['LI, LING', 'pids'] = '53/2189'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Papers</th>\n",
       "      <th>publications</th>\n",
       "      <th>pids</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WANG, XIZHAO</th>\n",
       "      <td>['Reduction of attributes in ordinal decision ...</td>\n",
       "      <td>38</td>\n",
       "      <td>02/4027</td>\n",
       "      <td>['02/4027', '02/4027', '02/4027', '02/4027', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WANG, XZ</th>\n",
       "      <td>['Neural network based fault diagnosis using u...</td>\n",
       "      <td>68</td>\n",
       "      <td>02/4027</td>\n",
       "      <td>['02/4027', '02/4027', '02/4027', '02/4027', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WANG, XI-ZHAO</th>\n",
       "      <td>['A research on weight acquisition of weighted...</td>\n",
       "      <td>47</td>\n",
       "      <td>02/4027</td>\n",
       "      <td>['02/4027', '02/4027', '02/4027', '02/4027', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZHU, SC</th>\n",
       "      <td>['Region competition: Unifying snakes, region ...</td>\n",
       "      <td>37</td>\n",
       "      <td>10/10313</td>\n",
       "      <td>['10/10313', '10/10313', '10/10313', '10/10313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZHU, SONG-CHUN</th>\n",
       "      <td>['Compositional boosting for computing hierarc...</td>\n",
       "      <td>127</td>\n",
       "      <td>10/10313</td>\n",
       "      <td>['10/10313', '10/10313', '10/10313', '10/10313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEUNG, DANIEL S.</th>\n",
       "      <td>['Sensitivity analysis of Madalines to weight ...</td>\n",
       "      <td>49</td>\n",
       "      <td>36/896</td>\n",
       "      <td>['36/896', '36/896', '36/896', '36/896', '36/8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEUNG, DS</th>\n",
       "      <td>['FUZZY KNOWLEDGE REPRESENTATION AND REASONING...</td>\n",
       "      <td>47</td>\n",
       "      <td>36/896</td>\n",
       "      <td>['36/896', '36/896', '36/896', '36/896', '36/8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YOSHUA BENGIO</th>\n",
       "      <td>['A Structured Self-Attentive Sentence Embeddi...</td>\n",
       "      <td>61</td>\n",
       "      <td>56/953</td>\n",
       "      <td>['56/953', '56/953', '56/953', '56/953', '56/9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BENGIO, YOSHUA</th>\n",
       "      <td>['Exploring Strategies for Training Deep Neura...</td>\n",
       "      <td>123</td>\n",
       "      <td>56/953</td>\n",
       "      <td>['56/953', '56/953', '56/953', '56/953', '56/9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEVINE, SERGEY</th>\n",
       "      <td>['Learning Complex Neural Network Policies wit...</td>\n",
       "      <td>64</td>\n",
       "      <td>80/7594</td>\n",
       "      <td>['80/7594', '80/7594', '80/7594', '80/7594', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERGEY LEVINE</th>\n",
       "      <td>['Learning Visual Servoing with Deep Features ...</td>\n",
       "      <td>76</td>\n",
       "      <td>80/7594</td>\n",
       "      <td>['80/7594', '80/7594', '80/7594', '80/7594', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LI, Y</th>\n",
       "      <td>['Generalized defuzzification strategies and t...</td>\n",
       "      <td>67</td>\n",
       "      <td>87/660</td>\n",
       "      <td>['87/660', '19/7778', '59/871', 'l/YongLi3', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LI, YAN</th>\n",
       "      <td>['Multi-layer support vector machine and its a...</td>\n",
       "      <td>103</td>\n",
       "      <td>87/660</td>\n",
       "      <td>['87/660', '87/660', '87/660', '87/660', '87/6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUANG, THOMAS S.</th>\n",
       "      <td>['Total variation models for variable lighting...</td>\n",
       "      <td>67</td>\n",
       "      <td>hThomasSHuang</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUANG, THOMAS</th>\n",
       "      <td>['A Convergent Solution to Tensor Subspace Lea...</td>\n",
       "      <td>41</td>\n",
       "      <td>hThomasSHuang</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAIN, AK</th>\n",
       "      <td>['CAD-BASED COMPUTER VISION - FROM CAD MODELS ...</td>\n",
       "      <td>46</td>\n",
       "      <td>jAnilKJain</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JAIN, ANIL K.</th>\n",
       "      <td>['Validating a biometric authentication system...</td>\n",
       "      <td>50</td>\n",
       "      <td>jAnilKJain</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUILLE, ALAN</th>\n",
       "      <td>['Unsupervised learning of object deformation ...</td>\n",
       "      <td>69</td>\n",
       "      <td>yAlanLYuille</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUILLE, ALAN L.</th>\n",
       "      <td>['Detecting object boundaries using low-, mid-...</td>\n",
       "      <td>38</td>\n",
       "      <td>yAlanLYuille</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Papers  \\\n",
       "Unnamed: 0                                                            \n",
       "WANG, XIZHAO      ['Reduction of attributes in ordinal decision ...   \n",
       "WANG, XZ          ['Neural network based fault diagnosis using u...   \n",
       "WANG, XI-ZHAO     ['A research on weight acquisition of weighted...   \n",
       "ZHU, SC           ['Region competition: Unifying snakes, region ...   \n",
       "ZHU, SONG-CHUN    ['Compositional boosting for computing hierarc...   \n",
       "YEUNG, DANIEL S.  ['Sensitivity analysis of Madalines to weight ...   \n",
       "YEUNG, DS         ['FUZZY KNOWLEDGE REPRESENTATION AND REASONING...   \n",
       "YOSHUA BENGIO     ['A Structured Self-Attentive Sentence Embeddi...   \n",
       "BENGIO, YOSHUA    ['Exploring Strategies for Training Deep Neura...   \n",
       "LEVINE, SERGEY    ['Learning Complex Neural Network Policies wit...   \n",
       "SERGEY LEVINE     ['Learning Visual Servoing with Deep Features ...   \n",
       "LI, Y             ['Generalized defuzzification strategies and t...   \n",
       "LI, YAN           ['Multi-layer support vector machine and its a...   \n",
       "HUANG, THOMAS S.  ['Total variation models for variable lighting...   \n",
       "HUANG, THOMAS     ['A Convergent Solution to Tensor Subspace Lea...   \n",
       "JAIN, AK          ['CAD-BASED COMPUTER VISION - FROM CAD MODELS ...   \n",
       "JAIN, ANIL K.     ['Validating a biometric authentication system...   \n",
       "YUILLE, ALAN      ['Unsupervised learning of object deformation ...   \n",
       "YUILLE, ALAN L.   ['Detecting object boundaries using low-, mid-...   \n",
       "\n",
       "                  publications           pids  \\\n",
       "Unnamed: 0                                      \n",
       "WANG, XIZHAO                38        02/4027   \n",
       "WANG, XZ                    68        02/4027   \n",
       "WANG, XI-ZHAO               47        02/4027   \n",
       "ZHU, SC                     37       10/10313   \n",
       "ZHU, SONG-CHUN             127       10/10313   \n",
       "YEUNG, DANIEL S.            49         36/896   \n",
       "YEUNG, DS                   47         36/896   \n",
       "YOSHUA BENGIO               61         56/953   \n",
       "BENGIO, YOSHUA             123         56/953   \n",
       "LEVINE, SERGEY              64        80/7594   \n",
       "SERGEY LEVINE               76        80/7594   \n",
       "LI, Y                       67         87/660   \n",
       "LI, YAN                    103         87/660   \n",
       "HUANG, THOMAS S.            67  hThomasSHuang   \n",
       "HUANG, THOMAS               41  hThomasSHuang   \n",
       "JAIN, AK                    46     jAnilKJain   \n",
       "JAIN, ANIL K.               50     jAnilKJain   \n",
       "YUILLE, ALAN                69   yAlanLYuille   \n",
       "YUILLE, ALAN L.             38   yAlanLYuille   \n",
       "\n",
       "                                                              names  \n",
       "Unnamed: 0                                                           \n",
       "WANG, XIZHAO      ['02/4027', '02/4027', '02/4027', '02/4027', '...  \n",
       "WANG, XZ          ['02/4027', '02/4027', '02/4027', '02/4027', '...  \n",
       "WANG, XI-ZHAO     ['02/4027', '02/4027', '02/4027', '02/4027', '...  \n",
       "ZHU, SC           ['10/10313', '10/10313', '10/10313', '10/10313...  \n",
       "ZHU, SONG-CHUN    ['10/10313', '10/10313', '10/10313', '10/10313...  \n",
       "YEUNG, DANIEL S.  ['36/896', '36/896', '36/896', '36/896', '36/8...  \n",
       "YEUNG, DS         ['36/896', '36/896', '36/896', '36/896', '36/8...  \n",
       "YOSHUA BENGIO     ['56/953', '56/953', '56/953', '56/953', '56/9...  \n",
       "BENGIO, YOSHUA    ['56/953', '56/953', '56/953', '56/953', '56/9...  \n",
       "LEVINE, SERGEY    ['80/7594', '80/7594', '80/7594', '80/7594', '...  \n",
       "SERGEY LEVINE     ['80/7594', '80/7594', '80/7594', '80/7594', '...  \n",
       "LI, Y             ['87/660', '19/7778', '59/871', 'l/YongLi3', '...  \n",
       "LI, YAN           ['87/660', '87/660', '87/660', '87/660', '87/6...  \n",
       "HUANG, THOMAS S.                                                NaN  \n",
       "HUANG, THOMAS                                                   NaN  \n",
       "JAIN, AK                                                        NaN  \n",
       "JAIN, ANIL K.                                                   NaN  \n",
       "YUILLE, ALAN                                                    NaN  \n",
       "YUILLE, ALAN L.                                                 NaN  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top[top.duplicated(subset=['pids'], keep=False)].sort_values('pids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<result>\n",
       "<query id=\"181828\">CONTEXT* AWARE* REASONING* MIDDLE* WARE* APPLIED* IN THE* MOBILE* ENVIRONMENT*</query>\n",
       "<status code=\"200\">OK</status>\n",
       "<time unit=\"msecs\">270.88</time>\n",
       "<completions computed=\"1\" sent=\"1\" total=\"1\">\n",
       "<c dc=\"1\" id=\"48913645\" oc=\"1\" sc=\"1\">environment</c>\n",
       "</completions>\n",
       "<hits computed=\"1\" first=\"0\" sent=\"1\" total=\"1\">\n",
       "<hit id=\"3605149\" score=\"10\">\n",
       "<info><authors><author pid=\"96/2744\">Jian Wu</author><author pid=\"69/1535\">Chunping Li</author><author pid=\"122/3274\">Yishu Miao</author><author pid=\"20/3883\">Shaoxu Song</author><author pid=\"53/2189\">Li Li</author><author pid=\"04/3021\">Qiang Ding</author></authors><title>Context-aware reasoning middle ware applied in the mobile environment.</title><venue>ICMLC</venue><pages>1829-1835</pages><year>2013</year><type>Conference and Workshop Papers</type><access>closed</access><key>conf/icmlc/WuLMSLD13</key><doi>10.1109/ICMLC.2013.6890894</doi><ee>https://doi.org/10.1109/ICMLC.2013.6890894</ee><url>https://dblp.org/rec/conf/icmlc/WuLMSLD13</url></info>\n",
       "<url>URL#3605149</url>\n",
       "</hit>\n",
       "</hits>\n",
       "</result>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top = pd.read_csv('./database/top1000authors.csv').sort_values(by='publications', ascending=False)\n",
    "# top.set_index('Unnamed: 0', inplace=True)\n",
    "name = 'LI, LI'\n",
    "i += 1\n",
    "pub = eval(top.loc[name]['Papers'])[i]\n",
    "url = f'https://dblp.org/search/publ/api?q={pub}&format=xml'\n",
    "request = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(request.text, 'xml')\n",
    "author_pids = list(map(lambda x: f\"{x['pid']} | {x.text}\" ,soup.findAll('author')))\n",
    "#author_pids[find_author(name, author_pids)]\n",
    "soup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fe3e6f0cdaab8afdc61c52912fda83f7c0a71baaea1897dd7498e2df01e69ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
