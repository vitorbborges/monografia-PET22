{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from gensim.matutils import kullback_leibler\n",
    "from gensim.models import ldamodel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from math import e\n",
    "\n",
    "from utils import dataset, load_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\n",
    "    'Publication Type', \\\n",
    "    'Venue', \\\n",
    "    'Author Full Names', \\\n",
    "    'Article Title', \\\n",
    "    'Abstract', \\\n",
    "    'Publication Date', \\\n",
    "    'Publication Year']\n",
    "\n",
    "venues = dataset()[col]\n",
    "venues = venues.dropna(subset=['Abstract'])\n",
    "venues['Abstract Lemmatized'] = load_bow('25_venues')\n",
    "venues = venues.dropna(subset=['Publication Date'])\n",
    "venues['Date'] = (venues['Publication Date']+'-'+venues['Publication Year']).apply(lambda x: datetime.strptime(x, '%b-%Y'))\n",
    "venues = venues.sort_values(by='Date')\n",
    "venues.index = range(len(venues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '60_asymmetric_auto_0.5_0.0075'\n",
    "model = ldamodel.LdaModel.load(f'models/lda_models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(bow):\n",
    "    return model.get_document_topics(model.id2word.doc2bow(bow), minimum_probability=0)\n",
    "venues['LDA Distribution'] = venues['Abstract Lemmatized'].apply(lambda x: get_topics(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = venues[['Date', 'LDA Distribution']]\n",
    "date_dict = {pd.Timestamp(i): (df['Date'][df['Date'] == i].index[0], df['Date'][df['Date'] == i].index[-1]) for i in df['Date'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Novelty(index, w):\n",
    "    start = df['Date'][index] - relativedelta(months=w)\n",
    "    end = df['Date'][index] - relativedelta(months=1)\n",
    "    if start > df['Date'].min():\n",
    "        date = df.iloc[date_dict[start][0]:date_dict[end][1]]\n",
    "        date['KLD'] = [kullback_leibler(df['LDA Distribution'][index], x) for x in date['LDA Distribution']]\n",
    "        nov = date.groupby('Date')['KLD'].mean().mean()*np.log2(e)\n",
    "        return nov\n",
    "    else: \n",
    "        return np.nan\n",
    "\n",
    "def Transience(index, w):\n",
    "    start = df['Date'][index] + relativedelta(months=1)\n",
    "    end = df['Date'][index] + relativedelta(months=w)\n",
    "    if end < df['Date'].max():\n",
    "        date = df.iloc[date_dict[start][0]:date_dict[end][1]]\n",
    "        date['KLD'] = [kullback_leibler(df['LDA Distribution'][index], x) for x in date['LDA Distribution']]\n",
    "        nov = date.groupby('Date')['KLD'].mean().mean()*np.log2(e)\n",
    "        return nov\n",
    "    else: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 1\n",
    "\n",
    "# Novelty\n",
    "df[f'Novelty_{w}'] = [Novelty(i, w) for i in tqdm(range(len(df)), desc=f'Novelty_{w}')]\n",
    "df.to_csv(f'KLD/distributions_{w}.csv', index=False)\n",
    "\n",
    "# Transience\n",
    "df[f'Transience_{w}'] = [Transience(i, w) for i in tqdm(range(len(df)), desc=f'Transience_{w}')]\n",
    "df.to_csv(f'KLD/distributions_{w}.csv', index=False)\n",
    "\n",
    "# Resonance\n",
    "df[f'Resonance_{w}'] = df[f'Novelty_{w}'] - df[f'Transience_{w}']\n",
    "df.to_csv(f'KLD/distributions_{w}.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fe3e6f0cdaab8afdc61c52912fda83f7c0a71baaea1897dd7498e2df01e69ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
